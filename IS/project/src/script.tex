%! Suppress = Unicode
%! Author = Adrian Helberg
%! Script = 18.02.2020
%! Presentation = 21.02.2020

%%% Preamble
\documentclass[11pt]{article}

%%% Packages
\usepackage{ngerman}
\usepackage{color} % Colored font
\usepackage{graphicx} % Images
\usepackage{titling} % Title formatting
\usepackage[utf8]{inputenc} % UTF-8
\usepackage {tikz} % Graphs

%%% Commands
% ToC title
\renewcommand{\contentsname}{
    \begin{center}
        \LARGE Inhalt
    \end{center}
}

%%% Title
\pretitle{
    \begin{center}
        \includegraphics[width=8cm]{../../resources/Haw_logo.png}
    \end{center}
}
\title{
    \begin{center}
        \Huge \textbf{Intelligente Systeme}\\
        {\color{blue}- Skript -}\\~\\
        \Large Prüfungsform: Referat
    \end{center}
}
\author{Adrian Helberg\\ Matr.Nr. 2309051}
\date{Abgabe: 18.02.2020}

%%% Document
\begin{document}

    \maketitle

    \begin{abstract}
        Diese Arbeit beschäftigt sich mit Konzepten der vier Kernbereiche aus \textit{intelligenten
        Systemen}: \textbf{Suchen}, \textbf{Lernen}, \textbf{Verarbeitung von Sequenzen} und
        \textbf{Ethik}. Zum einen werden Problemstellungen aufgezeigt, zum anderen auf
        Implementationen verwiesen, die in der zugehörigen Präsentation vorgestellt werden.\\ Eine
        Lösungsstrategie für das \textit{Problem des Handlungsreisenden (Traveling Salesman
        Problem)} wird im Kapitel \textbf{Suchen} beschrieben. \textit{Selbstorganisierte Karten
            (Selforganizing Maps)} zeigen eine Strategie des \textbf{Lernen}s, ein \textit{Deep
        Learning}- Ansatz zur Datenanalyse von Sensordaten mobiler Endgeräte gibt Einblicke in
        die \textbf{Sequenzverarbeitung} und eine Diskussion zum \textit{Trolley Problem} lädt
        zur Diskussion über die \textbf{Ethik} in Verbindung mit \textit{intelligenten Systemen}
        ein.
    \end{abstract}

    \tableofcontents
    \newpage

    \section{Suchen}

    Dieses Kapitel beschäftigt sich mit der Umsetzungen einer Lösungsstrategie für das
    \textit{Problem des Handlungsreisenden (Traveling Salesman Problem)} mithilfe einer
    informierten Suche. Im speziellen eine Umsetzung mit einem genetischen Algorithmus.

    \subsection{Problem des Handlungsreisenden}
    Das Problem des Handlungsreisenden ist ein kombinatorisches Optimierungsproblem der
    theoretischen Informatik. Dabei muss ein Handlungsreisender eine Menge von Städten besuchen.
    Er beginnt bei einer bestimmten Stadt und muss, nachdem jede andere Stadt besucht wurde, zu
    dieser zurückkehren. Das Optimierungsproblem besteht bei der Festlegung der Reihenfolge der zu
    besuchenden Städte, sodass die gesamte Distanz der Reise minimal ist. Das Problem ist als
    NP-vollständig klassifiziert.

    \subsection{Genetischer Algorithmus}
    Evolutionäre Algorithmen sind eine Klasse von stochastischen, heuristischen
    Optimierungsverfahren. Der Name lässt sich von der Evolution natürlicher Lebewesen ableiten.
    Ziel von genetischen Algorithmen ist es optimierte Lösungen zu Aufgabenstellungen zu finden,
    bei denen ein Auffinden einer akzeptablen Lösung aus Gründen der kombinatorischen Komplexität
    misslingt. So gibt es beim Problem des Handlungsreisenden mit 10 Orten z.B. bereits
    $10!=3628800$ Lösungen. Kern eines genetischen Ansatzes ist die Veränderung von Mengen an
    Problemlösungen, sodass gute Lösungen mit einer großen Wahrscheinlichkeit und schlechte
    Lösungen mit geringen Wahrscheinlichkeit erhalten bleiben. Das Zusammenführen von Teilen guter
    Lösungen kann noch bessere Ergebnisse liefern. So kann verhindert werden, dass ein
    Algorithmus zur Optimierung an einem lokalen Optimum "hängenbleibt".

    \newpage

    \subsubsection{Allgemeiner Ablauf}
    \begin{center}
        \begin{tikzpicture}[semithick , state/.style ={ rectangle ,top color =white , bottom color = processblue!20 ,
        draw,processblue , text=blue , minimum width =1 cm}]
            \node[state] (A) at (0,0) {Start};
            \node[state] (B) at (0,-1.2) {Erzeugung einer zufälliger Population};
            \node[state] (C) at (0,-2.4) {Wiederhole bis Abbruchbedungung erfüllt};
            \node[state] (D) at (0,-3.6) {Berechne Fitness};
            \node[state] (E) at (0,-4.8) {Selektion};
            \node[state] (F) at (0,-6) {Crossover};
            \node[state] (G) at (0,-7.2) {Mutation};
            \node[state] (H) at (0,-8.4) {Austausch};
            \node[state] (I) at (0,-9.6) {Teste Abbruchbedingung};
            \node[state] (J) at (0,-10.8) {Ende};

            \draw[->, very thick] (A) to (B);
            \draw[->, very thick] (B) to (C);
            \draw[->, very thick] (C) to (D);
            \draw[->, very thick] (D) to (E);
            \draw[->, very thick] (E) to (F);
            \draw[->, very thick] (F) to (G);
            \draw[->, very thick] (G) to (H);
            \draw[->, very thick] (H) to (I);
            \draw[->, very thick] (I) to (J);
        \end{tikzpicture}
    \end{center}

    \subsection{Chromosomen}
    Eine Rundreise des \textit{Handlungsreisenden} wird duch ein Chromosom repräsentiert. Er
    bereist hierzu alle Städte und endet in der Stadt, in der begonnen hat. Die Population
    besteht aus der Anzahl solcher Rundreisen, die durch Vektoren modelliert werden.\\
    Eine mögliche Rundreise wäre also:
    \left\{
    \begin{array}{c}
        3\\5\\1\\2\\4\\3
    \end{array}
    \right\}

    \subsection{Fitness}
    Eine Berechnung der Fitness in Abhängigkeit von der Gesamtdistanz einer Rundreise bietet sich
    für das \textit{Problem des Handlungsreisenden} an. Allerding soll der Fitness-Wert
    proportional zur Eignung (antiproportional zu den Kosten) eines Chromosoms sein. Für die
    Kosten wird die Gesamtdistanz eines Chromosoms, für die Fitness der inverse Kostenwert
    verwendet.

    \subsection{Selektion}
    Die Auswahl eines Chromosomenpaars aus der Population soll wahrscheinlicher werden, wenn der
    Fitness-Wert steigt. Dies kann mittels einer Summe über alle Fitness-Werte gleichverteilte
    Zufallszahl realisiert werden. Der Wertebereich der Zufallszahl wird in Abschnitte
    unterteilt, deren Größe genau den Fitnesswerten der einzelnen Chromosomen entsprechen. Der
    Abschnitt, in den die Zufallszahl fällt, bestimmt die Selektion des zugehörigen Chromosoms.

    \subsection{Kreuzung}
    Ein zufälliger Kreuzungspunkt innerhalb des Vektors eines selektierten Chromosoms wird bestimmt.
    Der neue Vektor ist bis zum Kreuzpunkt identisch mit dem ursprünglichen. Der restliche Teil
    des neuen Vektors wird wie folgt bestimmt. Gehe den zweiten ausgewählten Vektor vom Anfang
    bis zum Ende durch und füge die erste Zahl, die noch nicht im neu zu bildenden Chromosoms
    steht, an die nächste freie Stelle ein. An der letzten Stelle des neuen Chromosomes muss die
    gleiche Zahl stehen wie an seiner ersten Stelle. Dieser Prozess wird für beide ausgewählten
    Chromosomen durchgeführt.

    \subsection{Mutation}
    Mit einer kleinen Wahrscheinlichkeit findet in der Kreuzung eine Mutation statt. Diese wird
    wie folgt implementiert. Ein zufälliges Paar von Indizes mit Werten zwischen 1 und der Anzahl
    der Städte wird erzeugt. Die Werte, die den Indizes entsprechenm werden im Chromosom getauscht.
    Dabei darf die Eigenschaft, dass Start- und Zielwert identisch sind, nicht verletzt werden.

    \subsection{Austausch}
    In jeder Iteration werden in der Population die beiden schlechtesten Chromosomen, d.h.
    diejenigen mit den geringsten Fitness-Werten, durch die beiden neuen Chromosomen ersetzt, falls
    letztere bessere Fitness-Werte haben. Es wird gewährleistet, dass in der Population alle
    Chromosomen verschieden sind.

    \subsection{Realisierung mit Java}

    \subsubsection{Eigenschaften}
    \begin{center}
        \includegraphics[width=10cm]{../../resources/properties_algorithm.png}
        \\~\\
        \includegraphics[width=10cm]{../../resources/properties_results.png}
    \end{center}

    \subsubsection{Visualisierung}

    \begin{center}
        \includegraphics[width=10cm]{../../resources/tsp_cities.png}
        \\~\\
        \includegraphics[width=10cm]{../../resources/tsp_cities_connected.png}
    \end{center}

    \newpage

    \section{Lernen}

    Dieses Kapitel beschreibt ein unüberwachtes Lernverfahren der Neuroinformatik: Die
    \textit{Selbstorganisierenden Karten}, \textit{Kohonen-Karten}, oder \textit{Kohonen Feature
    Maps}. Also maschinelles Lernen ohne oder vorher bekannte Ergebniswerte.

    \subsection{Motivation}
    Das Funktionsprinzip von \textit{SOM}s (\textit{Self-organizing maps}) beruht auf der
    Erkenntnis, dass viele Strukturen im Gehirn eine lineare oder planare Topologie aufweisen.
    Eingehende Signale, wie z.B. visuelle Reize, sind jedoch multidimensional. Abbildung 1 zeigt
    eine Skizze der topologischen Ansicht des sensorischen Kotex, der die sensorischen Eingaben
    des Körpers auswertet. Es entsteht eine Klassifizierung, da ähnliche Ausgaben in direkter
    Umgebung angesiedelt werden. Beispielsweise sind Signale an die Finger in unmittelbarer
    Nachbarschaft zueinander. Solch eine Nachbarschaftsbeziehung zwischen Neuronen ist ein
    grundlegendes Merkmal von \textit{SOM}s

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=8cm]{../../resources/gehirn.png}
        \caption{Topologische Abbildung des sensorischen Kortex}
    \end{figure}
    \newpage

    Eine topologieerhaltende Abbildung auf weniger Dimensionen (siehe Kapitel
    \textbf{Motivation}), hier eine Fläche, wird als Karte bezeichnet. Diese Karten im Gehirn
    kommen bei allen Säugetieren vor und sind dynamisch. Dies wird an folgendem Beispiel deutlich.
    Beim Verlust von Körperteilen wird der Platz des entsprechenden Feldes mit der Zeit von
    anderen Feldern eingenommen (da die eingehenden Signale wegfallen, Abbildung 2).

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=12cm]{../../resources/aufbau.png}
        \caption{a) Schema einer Affenhand b) Bereich des Kortex der Hand c) 2 Monate nach
        Amputation von Finger D3}
    \end{figure}

    \subsection{Aufbau}
    \textit{SOM}s verwenden ein sehr einfaches Neuronenmodell ohne Aktivierungsfunktion
    (Abbildung 3)

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=12cm]{../../resources/neuron.png}
        \caption{Neuron einer \textit{SOM}}
    \end{figure}

    \subsection{Netz}
    Organisiert man Neuronen als Eingabe- und Ausgabeneuronen in jeweils einer
    Schicht, entsteht ein neuronales Netz, in dem die Eingabeneuronen über die Gewichtsvektoren
    komplett mit den Ausgabeneuronen verbunden sind (Abbildung 4).

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=12cm]{../../resources/netz.png}
        \caption{\textit{Kohonen}-Netz}
    \end{figure}

    \subsection{Lernverfahren}
    \textit{SOM}s lernen durch Auswahl eines Neurons anhand deren "`Eignung"'. Die Eignung wird
    über die euklidische Norm berechnet. Hierbei wird der Abstand zwischen Eingabevektor und
    Gewichtsvektor bestimmt. Besitzen Neuronen die gleiche euklidische Norm, wird über das
    Zufallsprinzip entschieden, welches Neuron ausgewählt wird. Das Besondere an \textit{SOM}s
    ist, dass nicht nur der Gewichtsvektor des ausgewählten Neurons (Siegerneuron) verändert
    wird, sondern auch die der Neuronen in der Umgebung des Siegerneurons.
    \newpage

    \subsection{Distanzfunktion}
    Anstelle der euklidischen Norm werden in der Praxis auch andere bewährte Distanzfunktionen
    verwendet. Einige Beispiele sind die gaussche Glockenfunktion, die Zylinderfunktion und der
    "`Mexican-Hat"' (Abbildung 5).

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=12cm]{../../resources/distanzfunktionen.png}
        \caption{Gaussche Glockenfunktion, Zylinderfunktion und Mexican-Hat}
    \end{figure}


    \subsection{Siegerneuron anpassen}
    $W_c = W_c + \Delta W_c$ und $\Delta W_c = \eta * (x-W_c)$, mit $c$ als Siegerneuron, $W_c$ als
    Gewichtungsvektor und Eingabevektor $x$. Es gilt $0 < \eta < 1$.


    \subsection{Nachbarneuron des Siegerneurons anpassen}
    Nachbarn des Siegerneurons lernen umso stärker, je näher sie sich am Siegerneuron befinden:\\~\\
    $\Delta W_j = \eta * h_c_j * (x - W_j)$
    \newpage

    \subsection{Visualisierung}
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=15cm]{../../resources/zoo_table.png}
        \caption{Beispiel "`Zoo"'}
    \end{figure}

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=12cm]{../../resources/zoo.png}
        \caption{Beispiel "`Zoo"'}
    \end{figure}
    Reduktion von mehreren Dimension auf 2 (Karte). Sind ähnliche Tiere eines Zoos benachbart?
    (Abbildung 6+7)

    \subsection{Anwendungsgebiete}
    \begin{itemize}
        \item Dimensionsreduktion
        \item Optimierung
        \item Data Mining- Cluster
        \item Data Mining - Regeln
        \item Überwachenung und Anomaliedetektion
        \item Kontextkarten
    \end{itemize}

    \section{Sequenzen}


    \section{Ethik}


    \section{Quellen}

\end{document}